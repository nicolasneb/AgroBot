# ðŸŒ¾ AgroBot â€” Sistema de Alertas ClimÃ¡ticas

Sistema de alertas climÃ¡ticas para el sector agrÃ­cola. Permite a los usuarios configurar umbrales de alerta sobre eventos meteorolÃ³gicos (heladas, granizo, lluvias intensas) y recibir notificaciones automÃ¡ticas cuando las condiciones climÃ¡ticas superan dichos umbrales.

Desarrollado con **FastAPI**, **SQLAlchemy (async)**, **PostgreSQL**, **Alembic** y **Docker**.

---

### Tabla de contenidos

- [Arquitectura](#arquitectura)
- [Modelo de datos](#modelo-de-datos)
- [Decisiones de diseÃ±o](#decisiones-de-diseÃ±o)
- [Requisitos](#requisitos)
- [InstalaciÃ³n y ejecuciÃ³n](#instalaciÃ³n-y-ejecuciÃ³n)
- [Comandos disponibles](#comandos-disponibles)
- [API Endpoints](#api-endpoints)
- [Tests](#tests)
- [Estructura del proyecto](#estructura-del-proyecto)

---

### Arquitectura

El proyecto sigue una **arquitectura en capas** combinada con los patrones **Repository**, **Service Layer** y **Observer**:

```
Request â†’ Router â†’ Service â†’ Repository â†’ Database
                      â†“
                   EventBus â†’ Handlers â†’ Notifications
```

| Capa | Responsabilidad |
|---|---|
| **Routers** | Reciben requests HTTP, validan input con Pydantic y delegan a los services |
| **Services** | Contienen la lÃ³gica de negocio y orquestan repositorios y eventos |
| **Repositories** | Abstraen el acceso a la base de datos (CRUD) |
| **EventBus** | Desacopla la generaciÃ³n de alertas de la creaciÃ³n de notificaciones (Observer pattern) |
| **Handlers** | Reaccionan a eventos emitidos por el EventBus |
| **Background Job** | EvalÃºa periÃ³dicamente las alertas activas contra los datos climÃ¡ticos |

---

### Modelo de Datos

El esquema se diseÃ±Ã³ con cinco entidades, cada una con una responsabilidad clara:

- **Users:** Representa a los usuarios del sistema. Se optÃ³ por incluir `phone` como identificador Ãºnico ya que el contexto de Agrobot es una interfaz de WhatsApp, donde el telÃ©fono es el canal principal de comunicaciÃ³n.

- **Fields:** Modela los campos de cada usuario. Se separÃ³ como entidad propia (en lugar de embeber la ubicaciÃ³n en el usuario) porque un mismo usuario puede tener mÃºltiples campos en distintas ubicaciones geogrÃ¡ficas, cada uno con condiciones climÃ¡ticas diferentes.

- **WeatherData:** Almacena los datos meteorolÃ³gicos que el job de ingesta persiste. Se diseÃ±Ã³ con `event_type` y `probability` como campos separados (en lugar de columnas fijas como `frost_probability`, `rain_probability`) para permitir agregar nuevos tipos de eventos climÃ¡ticos sin modificar el esquema de la base de datos. El campo `target_date` indica el dÃ­a al que refiere la predicciÃ³n.

- **Alerts:** Representa las alertas configuradas por los usuarios. Tiene FK tanto a `Users` como a `Fields` porque una alerta pertenece a un usuario y aplica sobre un campo especÃ­fico. No tiene FK directa a `WeatherData` ya que la relaciÃ³n es dinÃ¡mica: el background job vincula alertas con datos meteorolÃ³gicos en tiempo de ejecuciÃ³n a travÃ©s de `field_id` y `event_type`, evaluando si la `probability` supera el `threshold` configurado.

- **Notifications:** Registra las notificaciones generadas cuando una alerta se dispara. Tiene FK a `Users` (para consultar notificaciones por usuario) y a `Alerts` (para trazabilidad de quÃ© alerta la originÃ³). El campo `is_read` permite gestionar el estado de lectura desde el frontend.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          USERS           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id: UUID (PK)            â”‚
â”‚ name: String(100)        â”‚
â”‚ phone: String(20) UNIQUE â”‚
â”‚ created_at: DateTime     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
     â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚1    â”‚1                     â”‚1
     â”‚N    â”‚N                     â”‚N
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        FIELDS        â”‚  â”‚         ALERTS           â”‚  â”‚     NOTIFICATIONS        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id: UUID (PK)        â”‚  â”‚ id: UUID (PK)            â”‚  â”‚ id: UUID (PK)            â”‚
â”‚ user_id: UUID (FK)   â”‚  â”‚ user_id: UUID (FK)       â”‚  â”‚ user_id: UUID (FK)       â”‚
â”‚ name: String(100)    â”‚  â”‚ field_id: UUID (FK)      â”‚  â”‚ alert_id: UUID (FK)      â”‚
â”‚ latitude: Float      â”‚  â”‚ event_type: String(50)   â”‚  â”‚ message: String          â”‚
â”‚ longitude: Float     â”‚  â”‚ threshold: Float         â”‚  â”‚ is_read: Boolean         â”‚
â”‚ created_at: DateTime â”‚  â”‚ is_active: Boolean       â”‚  â”‚ created_at: DateTime     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ created_at: DateTime     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â–²
       â”‚                             â”‚                             â”‚
       â”‚1                            â”‚1                            â”‚N
       â”‚N                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              (Alerts 1â”€â”€N Notifications)
â”‚      WEATHER_DATA        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id: UUID (PK)            â”‚
â”‚ field_id: UUID (FK)      â”‚
â”‚ event_type: String(50)   â”‚
â”‚ probability: Float       â”‚
â”‚ target_date: Date        â”‚
â”‚ created_at: DateTime     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
```
Relaciones:
  Users     1â”€â”€N  Fields          (fields.user_id â†’ users.id)
  Users     1â”€â”€N  Alerts          (alerts.user_id â†’ users.id)
  Users     1â”€â”€N  Notifications   (notifications.user_id â†’ users.id)
  Fields    1â”€â”€N  WeatherData     (weather_data.field_id â†’ fields.id)
  Fields    1â”€â”€N  Alerts          (alerts.field_id â†’ fields.id)
  Alerts    1â”€â”€N  Notifications   (notifications.alert_id â†’ alerts.id)

Nota: No existe FK directa entre WeatherData y Alerts.
Se vinculan por lÃ³gica de negocio (field_id + event_type).
```

- **User**: Usuarios del sistema
- **Field**: Campos/parcelas asociados a un usuario con ubicaciÃ³n geogrÃ¡fica
- **WeatherData**: Datos meteorolÃ³gicos por campo y fecha (probabilidades de helada, granizo, lluvia)
- **Alert**: ConfiguraciÃ³n de umbrales por usuario, campo y tipo de evento
- **Notification**: Notificaciones generadas cuando un umbral es superado

---

## Decisiones de DiseÃ±o

El desarrollo del sistema comenzÃ³ con la definiciÃ³n de una **arquitectura por capas** (Routers â†’ Services â†’ Repositories â†’ Models), complementada con los patrones **Repository** y **Service Layer**, buscando una separaciÃ³n clara de responsabilidades que facilite el testing y la mantenibilidad del cÃ³digo.

Se incorporÃ³ el patrÃ³n **Observer** mediante un Event Bus para desacoplar la lÃ³gica de evaluaciÃ³n de alertas de la generaciÃ³n de notificaciones, permitiendo agregar nuevos handlers (logs, emails, webhooks) sin modificar el flujo principal.

El **modelo de datos** se diseÃ±Ã³ con cinco entidades (Users, Fields, WeatherData, Alerts, Notifications) donde WeatherData y Alerts no tienen FK directa entre sÃ­, sino que se vinculan por lÃ³gica de negocio a travÃ©s de `field_id` y `event_type`, reflejando que la relaciÃ³n es evaluada dinÃ¡micamente por el background job y no es una dependencia estructural.

Se eligiÃ³ **asincronÃ­a** de punta a punta (`AsyncSession`, `async/await` en repositorios, servicios y routers) para maximizar la concurrencia y evitar bloqueos del event loop, algo crÃ­tico en un sistema que combina endpoints HTTP con un job periÃ³dico corriendo en el mismo proceso.

El **background job** se implementÃ³ como una tarea asyncio dentro del lifespan de FastAPI, evaluando periÃ³dicamente los umbrales configurados contra los datos meteorolÃ³gicos y emitiendo eventos cuando se superan, sin necesidad de dependencias externas como Celery.

### Escalabilidad

Pensando en el crecimiento del sistema, se tomaron las siguientes decisiones:

- **Ãndices compuestos:** Se agregaron Ã­ndices como `ix_weather_field_event_date` sobre `field_id`, `event_type` y `target_date` para optimizar las consultas mÃ¡s frecuentes y evitar full table scans a medida que crece el volumen de datos meteorolÃ³gicos.
- **PaginaciÃ³n:** Se implementÃ³ en los endpoints de listado para controlar el tamaÃ±o de las respuestas y evitar la transferencia de grandes volÃºmenes de datos en una sola request.
- **Connection Pooling:** Se configurÃ³ en SQLAlchemy para reutilizar conexiones a la base de datos y evitar el overhead de abrir y cerrar conexiones en cada operaciÃ³n, fundamental bajo alta concurrencia.
- **EvaluaciÃ³n por lotes (batches):** El background job procesa las alertas en grupos controlados en lugar de cargar todas en memoria simultÃ¡neamente, evitando picos de consumo de recursos cuando la cantidad de alertas activas escala.

### Developer Experience

Se priorizÃ³ la experiencia del evaluador con:

- `Makefile` que centraliza todos los comandos del proyecto.
- `docker-compose` para levantar el entorno completo con un solo comando.
- Migraciones Alembic funcionales.
- Seed data con escenarios que disparan alertas reales.
- Tests que cubren desde repositorios hasta el flujo completo de evaluaciÃ³n.

---

### Requisitos

- **Docker Desktop** (incluye Docker Engine y Docker Compose)
- **make** (incluido en macOS/Linux; en Windows usar WSL2 o instalar con `choco install make`)

---

### InstalaciÃ³n y ejecuciÃ³n

```bash
# 1. Clonar el repositorio
git clone https://github.com/nicolasneb/AgroBot
cd agrobot

# 2. Levantar todo (build + migraciones + seed automÃ¡tico)
make init

# 3. Abrir la documentaciÃ³n interactiva
# http://localhost:8000/docs

# 4. Ver logs donde podremos observar las notificaciones (por default se ejecuta el job cada 60s)
make logs
```

La API estarÃ¡ disponible en `http://localhost:8000` y la documentaciÃ³n Swagger en `http://localhost:8000/docs`.

---

> **Nota:** Si el build falla con un error de snapshot (`parent snapshot does not exist`),
> ejecutar `docker builder prune -f` y reintentar con `make init`.
> Esta aclaracion esta hecha debido a que me encontre con dicho problema una vez a lo largo del desarrollo

### Comandos disponibles

| Comando | DescripciÃ³n |
|---|---|
| `make init` | Setup inicial: build, migraciones y levanta los servicios |
| `make build` | Rebuild y levanta los containers |
| `make up` | Levanta los containers (sin rebuild) |
| `make down` | Detiene los containers |
| `make restart` | Rebuild completo |
| `make reset` | Borra volÃºmenes y reinicia desde cero |
| `make logs` | Muestra logs de la API en tiempo real |
| `make shell` | Abre una terminal dentro del container de la API |
| `make db-shell` | Abre `psql` conectado a la base de datos |
| `make migrate` | Ejecuta las migraciones pendientes |
| `make migrate-create name="descripcion"` | Crea una nueva migraciÃ³n |
| `make migrate-history` | Muestra el historial de migraciones |
| `make migrate-downgrade` | Revierte la Ãºltima migraciÃ³n |
| `make seed` | Carga datos de prueba |
| `make test` | Ejecuta los tests |
| `make test-cov` | Ejecuta los tests con reporte de cobertura |

---

### API Endpoints

#### Users
| MÃ©todo | Ruta | DescripciÃ³n |
|---|---|---|
| `POST` | `/users/` | Crear usuario |
| `GET` | `/users/` | Listar usuarios |
| `GET` | `/users/{id}` | Obtener usuario por ID |

#### Fields
| MÃ©todo | Ruta | DescripciÃ³n |
|---|---|---|
| `POST` | `/fields/` | Crear campo |
| `GET` | `/fields/` | Listar campos |
| `GET` | `/fields/{id}` | Obtener campo por ID |
| `GET` | `/fields/user/{user_id}` | Campos de un usuario |

#### Weather Data
| MÃ©todo | Ruta | DescripciÃ³n |
|---|---|---|
| `POST` | `/weather/` | Registrar datos climÃ¡ticos |
| `GET` | `/weather/field/{field_id}` | Datos climÃ¡ticos de un campo |

#### Alerts
| MÃ©todo | Ruta | DescripciÃ³n |
|---|---|---|
| `POST` | `/alerts/` | Crear alerta |
| `GET` | `/alerts/user/{user_id}` | Alertas de un usuario |
| `GET` | `/alerts/{id}` | Obtener alerta por ID |
| `PUT` | `/alerts/{id}` | Actualizar alerta |
| `DELETE` | `/alerts/{id}` | Eliminar alerta |

#### Notifications
| MÃ©todo | Ruta | DescripciÃ³n |
|---|---|---|
| `GET` | `/notifications/user/{user_id}` | Notificaciones de un usuario |
| `PATCH` | `/notifications/{id}/read` | Marcar como leÃ­da |

#### Health
| MÃ©todo | Ruta | DescripciÃ³n |
|---|---|---|
| `GET` | `/health` | Estado de la API y conectividad a la DB |

---

### Tests

```bash
# Ejecutar todos los tests
make test

# Tests con reporte de cobertura
make test-cov
```


Los tests cubren:

- **Repositories**: CRUD de cada entidad contra la base de datos de test
- **Services**: LÃ³gica de negocio de alertas y evaluaciÃ³n
- **Routers**: Tests de integraciÃ³n de todos los endpoints (happy path + errores)
- **EventBus**: EmisiÃ³n de eventos y ejecuciÃ³n de handlers
- **Handlers**: AcumulaciÃ³n y flush de notificaciones
- **Background Job**: EjecuciÃ³n periÃ³dica del servicio de evaluaciÃ³n
- **Seed**: Idempotencia de la carga de datos

---

### Variables de Entorno

El archivo `.env` en la raÃ­z del proyecto configura todo el sistema. A continuaciÃ³n el detalle de cada variable:

> **Nota:** Deje subido el .env para este challenge ya que facilita levantar el entorno rÃ¡pidamente soy consciente de que no es una buena practica dejarlo, esta comentada la linea referida el .env en el .gitignore

#### PostgreSQL

| Variable | DescripciÃ³n | Default |
|---|---|---|
| `POSTGRES_USER` | Usuario de la base de datos | `postgres` |
| `POSTGRES_PASSWORD` | ContraseÃ±a de la base de datos | `postgres` |
| `POSTGRES_DB` | Nombre de la base de datos | `agrobot` |
| `POSTGRES_PORT` | Puerto de PostgreSQL | `5432` |

#### Application

| Variable | DescripciÃ³n | Default |
|---|---|---|
| `DATABASE_URL` | Connection string async para SQLAlchemy (`asyncpg`) | Compuesta desde las variables de PostgreSQL |
| `TEST_DATABASE_URL` | Connection string async para la base de datos de tests | `""` (vacÃ­o) |
| `ALEMBIC_DATABASE_URL` | Connection string sync para Alembic (`psycopg2`) | `""` (vacÃ­o) |

#### Background Job

| Variable | DescripciÃ³n | Default |
|---|---|---|
| `EVALUATION_INTERVAL_SECONDS` | Intervalo en segundos entre cada ejecuciÃ³n del job de evaluaciÃ³n de alertas | `60` |

> **Nota:** Las variables `DATABASE_URL`, `TEST_DATABASE_URL` y `ALEMBIC_DATABASE_URL` se componen dinÃ¡micamente usando interpolaciÃ³n de variables en el `.env`. No es necesario modificarlas directamente, basta con ajustar las variables de PostgreSQL.
>
> Se usan dos drivers distintos porque SQLAlchemy async requiere `asyncpg` mientras que Alembic opera de forma sincrÃ³nica con `psycopg2`.

---

### cURL Examples

El archivo `curls.sh` contiene todos los comandos para probar la API.

---

### Estructura del proyecto

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                  # Entry point, lifespan, routers
â”‚   â”œâ”€â”€ config.py                # Settings (pydantic-settings)
â”‚   â”œâ”€â”€ database.py              # AsyncSession factory
â”‚   â”œâ”€â”€ errors.py                # Excepciones custom y error handlers
â”‚   â”œâ”€â”€ models/                  # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ field.py
â”‚   â”‚   â”œâ”€â”€ weather_data.py
â”‚   â”‚   â”œâ”€â”€ alert.py
â”‚   â”‚   â””â”€â”€ notification.py
â”‚   â”œâ”€â”€ schemas/                 # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ field.py
â”‚   â”‚   â”œâ”€â”€ weather_data.py
â”‚   â”‚   â”œâ”€â”€ alert.py
â”‚   â”‚   â””â”€â”€ notification.py
â”‚   â”œâ”€â”€ repositories/            # Data access layer
â”‚   â”‚   â”œâ”€â”€ user_repo.py
â”‚   â”‚   â”œâ”€â”€ field_repo.py
â”‚   â”‚   â”œâ”€â”€ weather_repo.py
â”‚   â”‚   â”œâ”€â”€ alert_repo.py
â”‚   â”‚   â””â”€â”€ notification_repo.py
â”‚   â”œâ”€â”€ services/                # Business logic
â”‚   â”‚   â”œâ”€â”€ alert_service.py
â”‚   â”‚   â””â”€â”€ evaluation_service.py
â”‚   â”œâ”€â”€ routers/                 # HTTP endpoints
â”‚   â”‚   â”œâ”€â”€ users.py
â”‚   â”‚   â”œâ”€â”€ fields.py
â”‚   â”‚   â”œâ”€â”€ weather.py
â”‚   â”‚   â”œâ”€â”€ alerts.py
â”‚   â”‚   â””â”€â”€ notifications.py
â”‚   â”œâ”€â”€ events/                  # Observer pattern
â”‚   â”‚   â”œâ”€â”€ event_bus.py
â”‚   â”‚   â”œâ”€â”€ events.py
â”‚   â”‚   â””â”€â”€ handlers/
â”‚   â”‚       â”œâ”€â”€ notification_handler.py
â”‚   â”‚       â””â”€â”€ log_handler.py
â”‚   â”œâ”€â”€ jobs/                    # Background tasks
â”‚   â”‚   â””â”€â”€ evaluate_alerts.py
â”‚   â”œâ”€â”€ seeds/                   # Seed data
â”‚   â”‚   â””â”€â”€ seed_data.py
â”‚   â””â”€â”€ tests/                   # Test suite
â”‚       â”œâ”€â”€ conftest.py
â”‚       â”œâ”€â”€ test_user_repo.py
â”‚       â”œâ”€â”€ test_field_repo.py
â”‚       â”œâ”€â”€ test_alert_repo.py
â”‚       â”œâ”€â”€ test_notification_repo.py
â”‚       â”œâ”€â”€ test_alert_service.py
â”‚       â”œâ”€â”€ test_evaluation_service.py
â”‚       â”œâ”€â”€ test_event_bus.py
â”‚       â”œâ”€â”€ test_handlers.py
â”‚       â”œâ”€â”€ test_routers.py
â”‚       â”œâ”€â”€ test_job.py
â”‚       â””â”€â”€ test_seed.py
â”œâ”€â”€ alembic/                     # Database migrations
â”‚   â”œâ”€â”€ env.py
â”‚   â””â”€â”€ versions/
â”œâ”€â”€ alembic.ini
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Makefile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
